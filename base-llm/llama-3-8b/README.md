# Use of OntoGenix prompt with the Llama-3-8B

## Setting up Llama-3-8B

**LLaMA-3** is the third generation of large-scale language models developed by Meta AI, designed for advanced natural language processing (NLP) tasks.  This family of models includes 8 billion (8B) and 70 billion (70B) parameter versions, with pre-trained and instruction-tuned variants. The LLaMA-3 models are optimized for text and code generation and excel in dialog tasks. 

For the experiment, the instructional version of **Llama-3-8b**, called **Meta-Llama-3-8B-Instruct**, has been used, which is an instruction-tuned version of the Llama-3-8b model and has been specifically trained and optimized for dialog tasks, where the model needs to interpret instructions and generate useful responses. This fine-tuning ensures that the model not only generates consistent text, but also better follows user prompts. 

To optimize the use of hardware resources, the model was quantized to **8 bits**, a technique that reduces the accuracy of both the computations and the data stored in the model. This process significantly reduces the memory and computational requirements of the model without noticeably compromising its performance or accuracy on the tasks for which it was trained. By reducing the bit width, quantization increases the efficiency of storage, computation, and power consumption, allowing the model to be implemented on less powerful hardware or at a lower cost, while still providing high quality ontology generation results.

## Adaptation of OntoGenix prompts

We have adapted the OntoGenix prompts to the format of the official Llama 3 template. To do this, we used the AutoTokenizer class from the Transformers library, which allows us to use the conversation template defined by the model. These conversation templates are part of the tokenizer and specify how to convert interactions represented as lists of messages into a tokenizable text string according to the format expected by the model.

In a conversation context, instead of continuing a single text string (as in standard language templates), the template continues a conversation consisting of one or more messages, each with a defined role. These roles include

- **System**: Defines the function the template is to perform. Provides guidelines or instructions on how the template should behave in the conversation.
- **User**: Represents the user input or prompt, i.e. the task to be performed or the question to be answered.
- **Assistant**: Represents the response to be generated by the model, providing the information or answer requested by the user.

The official template follows this format:

```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

{{ system_prompt }}<|eot_id|><|start_header_id|>user<|end_header_id|>

{{ user_message }}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
```

This format ensures that each interaction follows a consistent flow between roles and that the information provided by the model is consistent with the user prompt and the instructions set in the system field.

## Results obtained

### Airlines Customer satisfaction

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-8b/AirlinesCustomerSatisfaction

Description: Customers who have already flown with them, including the feedback of the customers on various contexts. 

Analysis: 

### Amazon Rating

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-8b/AmazonRating

Description: Customer reviews and ratings of Beauty related products sold on their website.

Analysis: 

### BigBasket Products

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-8b/BigBasketProducts

Description: Products listed on the website of online grocery store Big Basket.

Analysis: 

###  Brazilian e-commerce

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-8b/BrazilianE-commerce

Description: Brazilian e-commerce public dataset of orders made at Olist Store.

Analysis: 

### Customer complaint

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-8b/CustomerComplaint

Description: Collection of complaints about consumer financial products.

Analysis: 

### E-commerce

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-8b/eCommerce

Description: Transactions for a UK-based and registered non-store online retail.

Analysis: 

## Summary of the findings

- Being a newer model with more parameters than Llama-2, it better understands the instructions for both ontology generation and mapping.
- It produces certain hallucinations in the mapping part, for example, it adds a few more characters or changes some characters for others. 
