# Use of OntoGenix prompt with the Llama-3-70B

## Setting up Llama-3-70B

**LLaMA-3** is the third generation of large-scale language models developed by Meta AI, designed for advanced natural language processing (NLP) tasks.  This family of models includes 8 billion (8B) and 70 billion (70B) parameter versions, with pre-trained and instruction-tuned variants. The LLaMA-3 models are optimized for text and code generation and excel in dialog tasks. 

The experiment used the instructional version of Llama-3-70b, called **meta-llama/Meta-Llama-3-70B-Instruct** an autoregressive linguistic model with an optimized transform architecture. Supervised fine-tuning (SFT) and machine reinforcement learning with human feedback (RLHF) have been used to adapt to human preferences in terms of utility and security. In this version, the model has a total of 70 billion parameters, occupying about 147 GB. Unlike Llama-2, the context in this version has been increased from 4k to 8k.

To maximize hardware resource utilization, the model has been quantized to **4 bits**, enhancing its efficiency during inference. Additionally, inference was performed using four NVIDIA RTX 4090 GPUs, each equipped with 24 GB of VRAM. Quantization reduces the precision of the model's computations and data storage without substantially impacting its performance or accuracy in the tasks it was trained for. This approach makes the model more efficient in terms of storage, computation, and power consumption, while preserving a high level of performance.

## Adaptation of OntoGenix prompts

We have adapted the OntoGenix prompts to the format of the official Llama 3 template. To do this, we used the AutoTokenizer class from the Transformers library, which allows us to use the conversation template defined by the model. These conversation templates are part of the tokenizer and specify how to convert interactions represented as lists of messages into a tokenizable text string according to the format expected by the model.

In a conversation context, instead of continuing a single text string (as in standard language templates), the template continues a conversation consisting of one or more messages, each with a defined role. These roles include

- **System**: Defines the function the template is to perform. Provides guidelines or instructions on how the template should behave in the conversation.
- **User**: Represents the user input or prompt, i.e. the task to be performed or the question to be answered.
- **Assistant**: Represents the response to be generated by the model, providing the information or answer requested by the user.

The official template follows this format:

```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

{{ system_prompt }}<|eot_id|><|start_header_id|>user<|end_header_id|>

{{ user_message }}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
```

This format ensures that each interaction follows a consistent flow between roles and that the information provided by the model is consistent with the user prompt and the instructions set in the system field.

## Results obtained

### Airlines Customer satisfaction

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-70b/AirlinesCustomerSatisfaction

Description: Customers who have already flown with them, including the feedback of the customers on various contexts. 

Analysis: 

### Amazon Rating

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-70b/AmazonRating

Description: Customer reviews and ratings of Beauty related products sold on their website.

Analysis: 

### BigBasket Products

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-70b/BigBasketProducts

Description: Products listed on the website of online grocery store Big Basket.

Analysis: 

###  Brazilian e-commerce

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-70b/BrazilianE-commerce

Description: Brazilian e-commerce public dataset of orders made at Olist Store.

Analysis: 

### Customer complaint

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-70b/CustomerComplaint

Description: Collection of complaints about consumer financial products.

Analysis: 

### E-commerce

Link: https://github.com/tecnomod-um/OntoGenixOpenSourceLLM/tree/main/base-llm/llama-3-70b/eCommerce

Description: Transactions for a UK-based and registered non-store online retail.

Analysis: 

## Summary of the findings

- As a 70B parameter model, we had to quantize it to 4 bits due to the limited hardware resources available, which reduced its accuracy in generating ontogies, high-level description and mapping.
- It works better than Llama-3-8b in generating ontologies in TURTLE format.

